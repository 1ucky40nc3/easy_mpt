{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMTH3sBT6dQabIeFcjmK22I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1ucky40nc3/easy_mpt/blob/main/examples/notebooks/run_mpt_with_ctransformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjCG-pOAhsTz"
      },
      "outputs": [],
      "source": [
        "# @title Install Requirements\n",
        "!pip install einops\n",
        "!pip install transformers\n",
        "!pip install accelerate\n",
        "!pip install sentencepiece\n",
        "!pip install ctransformers\n",
        "\n",
        "!git lfs install"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Clone the ggml Repository\n",
        "!git clone https://github.com/ggerganov/ggml"
      ],
      "metadata": {
        "id": "vvxgEDkGh6w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Build the ggml MPT Features\n",
        "!mkdir -p /content/ggml/build\n",
        "%cd /content/ggml/build\n",
        "!cmake ..\n",
        "!make -j4 mpt mpt-quantize"
      ],
      "metadata": {
        "id": "j5TM8ERNh9Nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download the `mosaicml/mpt-7b-instruct` PLM\n",
        "!mkdir -p /content/models\n",
        "%cd /content/models\n",
        "!git clone https://huggingface.co/mosaicml/mpt-7b-instruct"
      ],
      "metadata": {
        "id": "6hJbUHIOh_Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Convert the PLM into the ggml Format\n",
        "%cd /content/ggml/build\n",
        "!python ../examples/mpt/convert-h5-to-ggml.py /content/models/mpt-7b-instruct 0"
      ],
      "metadata": {
        "id": "MNO_i8HpiAjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Quantize the PLM\n",
        "%cd /content/ggml/build\n",
        "!./bin/mpt-quantize \\\n",
        "    /content/models/mpt-7b-instruct/ggml-model-f32.bin \\\n",
        "    /content/models/mpt-7b-instruct/model-quant.bin \\\n",
        "    q4_0"
      ],
      "metadata": {
        "id": "4dgdPH3Hthb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Import Dependencies\n",
        "from ctransformers import AutoModelForCausalLM"
      ],
      "metadata": {
        "id": "A9IjB1Ow1Upb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load the GGML **MosaicML MPT-7B-Instruct** model in *fp32*\n",
        "llm_fp32 = AutoModelForCausalLM.from_pretrained(\n",
        "    \"/content/models/mpt-7b-instruct/ggml-model-f32.bin\", \n",
        "    model_type=\"mpt\"\n",
        ")"
      ],
      "metadata": {
        "id": "Pxh79DtkiDcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Do some Inference\n",
        "llm_fp32(\"AI is going to\")"
      ],
      "metadata": {
        "id": "uY6_6ihAuQ90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load the *Quantized* GGML **MosaicML MPT-7B-Instruct**\n",
        "llm_quant = AutoModelForCausalLM.from_pretrained(\n",
        "    \"/content/models/mpt-7b-instruct/model-quant.bin\", \n",
        "    model_type=\"mpt\"\n",
        ")"
      ],
      "metadata": {
        "id": "r9ykV9dwvWLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Do some Inference\n",
        "llm_quant(\"AI is going to\")"
      ],
      "metadata": {
        "id": "oIulSWz6voqk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}